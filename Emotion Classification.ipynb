{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import string \n",
    "import re \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Chaitanya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data \n",
    "train=pd.read_csv('train_data.txt',sep=';',header=None)\n",
    "test=pd.read_csv('test_data.txt',sep=';',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "train.to_csv('train.csv')\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying column names\n",
    "train.columns = ['text', 'emotion'] \n",
    "test.columns = ['text', 'emotion'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for class imbalance\n",
    "train.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text to lowercase\n",
    "train[\"text\"] = train[\"text\"].str.lower()\n",
    "test[\"text\"] = test[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to remove the punctuation\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(lambda text: remove_punctuation(text))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda text: remove_punctuation(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to remove the stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(lambda text: remove_stopwords(text))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmetizing words in each sentence\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(lambda text: lemmatize_words(text))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     didnt feel humiliate\n",
       "1        go feeling hopeless damn hopeful around someon...\n",
       "2                    im grab minute post feel greedy wrong\n",
       "3        ever feel nostalgic fireplace know still property\n",
       "4                                             feel grouchy\n",
       "                               ...                        \n",
       "15995         brief time beanbag say anna feel like beaten\n",
       "15996    turn feel pathetic still wait table sub teach ...\n",
       "15997                             feel strong good overall\n",
       "15998                       feel like rude comment im glad\n",
       "15999                         know lot feel stupid portray\n",
       "Name: text, Length: 16000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.text\n",
    "y_train=train.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test.text\n",
    "y_test=test.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing text\n",
    "def tokenize(data):\n",
    "    result=[]\n",
    "    for sentence in data:\n",
    "        result_sentence=[]\n",
    "        result_sentence=nltk.word_tokenize(sentence)\n",
    "        result.append(result_sentence)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok= tokenize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tok=tokenize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing Tfidf features\n",
    "v = TfidfVectorizer()\n",
    "xtr = v.fit_transform(X_train)\n",
    "xts= v.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaaaaaand',\n",
       " 'aaaaand',\n",
       " 'aaaand',\n",
       " 'aac',\n",
       " 'aahhh',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abandonment',\n",
       " 'abate',\n",
       " 'abbigail',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abduct',\n",
       " 'abelard',\n",
       " 'abhorrent',\n",
       " 'abide',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'able',\n",
       " 'ableness',\n",
       " 'abnormally',\n",
       " 'aboard',\n",
       " 'abominable',\n",
       " 'abortion',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'abraham',\n",
       " 'abroad',\n",
       " 'abruptly',\n",
       " 'absence',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutly',\n",
       " 'absorb',\n",
       " 'abstain',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusive',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'acause',\n",
       " 'accelerate',\n",
       " 'accent',\n",
       " 'accentuate',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessary',\n",
       " 'accessibility',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'acclimate',\n",
       " 'acco',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'account',\n",
       " 'accrue',\n",
       " 'acctually',\n",
       " 'accumulate',\n",
       " 'accumulation',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'accuser',\n",
       " 'accustom',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'ache',\n",
       " 'acheivment',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'aching',\n",
       " 'achy',\n",
       " 'acim',\n",
       " 'acker',\n",
       " 'acknowledge',\n",
       " 'acknowledgement',\n",
       " 'acknowledgment',\n",
       " 'acne',\n",
       " 'aconfident',\n",
       " 'acquaint',\n",
       " 'acquaintance',\n",
       " 'acquire',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actauly',\n",
       " 'action',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'acuity',\n",
       " 'acumen',\n",
       " 'acutely',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adaption',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addison',\n",
       " 'addisons',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'addle',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'ade',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adf',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjust',\n",
       " 'adjustment',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'administrator',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admires',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admittance',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'adn',\n",
       " 'adolescence',\n",
       " 'adomen',\n",
       " 'adopt',\n",
       " 'adoption',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adores',\n",
       " 'adrasteius',\n",
       " 'adrenaline',\n",
       " 'adress',\n",
       " 'adrift',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advantage',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventurous',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'advertise',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'aesthetic',\n",
       " 'afaerytaleinmakebelieve',\n",
       " 'affair',\n",
       " 'affeccion',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affend',\n",
       " 'affiliate',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'affords',\n",
       " 'afghan',\n",
       " 'afield',\n",
       " 'aforementioned',\n",
       " 'afp',\n",
       " 'afrad',\n",
       " 'afrade',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'aftereffect',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggravate',\n",
       " 'aggravated',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'agiatated',\n",
       " 'agility',\n",
       " 'agitate',\n",
       " 'agitated',\n",
       " 'agnostic',\n",
       " 'ago',\n",
       " 'agonise',\n",
       " 'agonize',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreement',\n",
       " 'agtalk',\n",
       " 'ah',\n",
       " 'ahaha',\n",
       " 'ahahahaha',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahhh',\n",
       " 'ahkman',\n",
       " 'aid',\n",
       " 'aiiiiighhhht',\n",
       " 'ailment',\n",
       " 'aim',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'aircleaner',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airritated',\n",
       " 'airtime',\n",
       " 'aiw',\n",
       " 'aj',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'akron',\n",
       " 'aku',\n",
       " 'akward',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alaska',\n",
       " 'alba',\n",
       " 'albeit',\n",
       " 'albino',\n",
       " 'album',\n",
       " 'albuquerque',\n",
       " 'alcest',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alec',\n",
       " 'alene',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexander',\n",
       " 'alexis',\n",
       " 'alfred',\n",
       " 'algebra',\n",
       " 'alhamdulillah',\n",
       " 'ali',\n",
       " 'alibi',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alight',\n",
       " 'align',\n",
       " 'aligncenter',\n",
       " 'alignment',\n",
       " 'alise',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allegation',\n",
       " 'allen',\n",
       " 'allergen',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alley',\n",
       " 'alli',\n",
       " 'alliance',\n",
       " 'alll',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowfullscreen',\n",
       " 'allthingsbucks',\n",
       " 'allusion',\n",
       " 'ally',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'aloft',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'alotta',\n",
       " 'alphabet',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alsways',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'altogether',\n",
       " 'alton',\n",
       " 'aluminum',\n",
       " 'alva',\n",
       " 'alway',\n",
       " 'always',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazingness',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'ambleside',\n",
       " 'ambulance',\n",
       " 'ambulatory',\n",
       " 'amd',\n",
       " 'amenity',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amits',\n",
       " 'amkris',\n",
       " 'amma',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amorous',\n",
       " 'amorphous',\n",
       " 'amos',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amparo',\n",
       " 'ampatuan',\n",
       " 'amped',\n",
       " 'ample',\n",
       " 'amplify',\n",
       " 'amsterdam',\n",
       " 'amud',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amvassago',\n",
       " 'amy',\n",
       " 'anaesthetic',\n",
       " 'anal',\n",
       " 'analogy',\n",
       " 'analyse',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'anansi',\n",
       " 'anatomy',\n",
       " 'ancestral',\n",
       " 'anchorage',\n",
       " 'ancient',\n",
       " 'andangry',\n",
       " 'andare',\n",
       " 'andintrupte',\n",
       " 'andover',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andrew',\n",
       " 'andri',\n",
       " 'andthenwear',\n",
       " 'andy',\n",
       " 'anesthetize',\n",
       " 'angee',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'anger',\n",
       " 'angered',\n",
       " 'angie',\n",
       " 'angle',\n",
       " 'angled',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'angsty',\n",
       " 'anguish',\n",
       " 'animal',\n",
       " 'animated',\n",
       " 'anime',\n",
       " 'animesh',\n",
       " 'animosity',\n",
       " 'anipike',\n",
       " 'ankle',\n",
       " 'anklet',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'annotation',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoyingly',\n",
       " 'annual',\n",
       " 'annulment',\n",
       " 'ano',\n",
       " 'anonymous',\n",
       " 'anotehr',\n",
       " 'another',\n",
       " 'anothers',\n",
       " 'ansi',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antagonism',\n",
       " 'anthem',\n",
       " 'anthology',\n",
       " 'anti',\n",
       " 'antic',\n",
       " 'anticipate',\n",
       " 'anticipation',\n",
       " 'antidepressant',\n",
       " 'antidote',\n",
       " 'antipasti',\n",
       " 'antique',\n",
       " 'antiquity',\n",
       " 'antisocial',\n",
       " 'antm',\n",
       " 'antoinette',\n",
       " 'antonio',\n",
       " 'antsy',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyones',\n",
       " 'anything',\n",
       " 'anythings',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'aoa',\n",
       " 'aoi',\n",
       " 'aol',\n",
       " 'aout',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apathetic',\n",
       " 'apathy',\n",
       " 'apawa',\n",
       " 'apaya',\n",
       " 'apc',\n",
       " 'apendages',\n",
       " 'apgujeong',\n",
       " 'apocalypse',\n",
       " 'apologetic',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologizes',\n",
       " 'apology',\n",
       " 'apostrophe',\n",
       " 'apothecary',\n",
       " 'app',\n",
       " 'appal',\n",
       " 'appalled',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearanc',\n",
       " 'appearance',\n",
       " 'appease',\n",
       " 'appetite',\n",
       " 'apple',\n",
       " 'applebees',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehensive',\n",
       " 'appriciation',\n",
       " 'apprise',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approx',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appts',\n",
       " 'apraxia',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arc',\n",
       " 'arcade',\n",
       " 'arch',\n",
       " 'archdiocese',\n",
       " 'archeological',\n",
       " 'architect',\n",
       " 'architectural',\n",
       " 'architecturally',\n",
       " 'ardmore',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'arent',\n",
       " 'aretha',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'ariel',\n",
       " 'arise',\n",
       " 'arist',\n",
       " 'arlovski',\n",
       " 'arm',\n",
       " 'armani',\n",
       " 'armistice',\n",
       " 'armor',\n",
       " 'armpit',\n",
       " 'army',\n",
       " 'aroma',\n",
       " 'around',\n",
       " 'arouse',\n",
       " 'aroused',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrangment',\n",
       " 'array',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'arse',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'artefacts',\n",
       " 'article',\n",
       " 'articulate',\n",
       " 'artifically',\n",
       " 'artificial',\n",
       " 'artificially',\n",
       " 'artisan',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artistry',\n",
       " 'artwork',\n",
       " 'arty',\n",
       " 'arugh',\n",
       " 'arun',\n",
       " 'arvo',\n",
       " 'aryan',\n",
       " 'aryiku',\n",
       " 'as',\n",
       " 'asami',\n",
       " 'asasoulawakens',\n",
       " 'asbestos',\n",
       " 'asciatic',\n",
       " 'asd',\n",
       " 'ash',\n",
       " 'ashame',\n",
       " 'ashamed',\n",
       " 'ashers',\n",
       " 'ashley',\n",
       " 'ashlotte',\n",
       " 'ashraf',\n",
       " 'ashton',\n",
       " 'ashtray',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asma',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'aspieness',\n",
       " 'aspire',\n",
       " 'ass',\n",
       " 'assassinate',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assemble',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'assertive',\n",
       " 'assess',\n",
       " 'assessment',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'association',\n",
       " 'assuage',\n",
       " 'assume',\n",
       " 'assumption',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'assuredly',\n",
       " 'astonishment',\n",
       " 'astray',\n",
       " 'asylum',\n",
       " 'ata',\n",
       " 'atari',\n",
       " 'ate',\n",
       " 'atelier',\n",
       " 'atell',\n",
       " 'atention',\n",
       " 'ath',\n",
       " 'athe',\n",
       " 'atheism',\n",
       " 'atheist',\n",
       " 'athf',\n",
       " 'athlete',\n",
       " 'athletic',\n",
       " 'athleticism',\n",
       " 'athletics',\n",
       " 'atiqah',\n",
       " 'ativan',\n",
       " 'atlanta',\n",
       " 'atleast',\n",
       " 'atlephobia',\n",
       " 'atletico',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atom',\n",
       " 'atomic',\n",
       " 'atop',\n",
       " 'atoshealthcare',\n",
       " 'atrocious',\n",
       " 'atrophy',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attain',\n",
       " 'attainable',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attic',\n",
       " 'atticus',\n",
       " 'attire',\n",
       " 'attitude',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attribute',\n",
       " 'au',\n",
       " 'aubrey',\n",
       " 'auction',\n",
       " 'audacity',\n",
       " 'audie',\n",
       " 'audience',\n",
       " 'audiobooks',\n",
       " 'audre',\n",
       " 'auggie',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aunty',\n",
       " 'aussie',\n",
       " 'aussy',\n",
       " 'austen',\n",
       " 'auster',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'authentic',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authoritative',\n",
       " 'authority',\n",
       " 'autism',\n",
       " 'autistic',\n",
       " 'autistics',\n",
       " 'auto',\n",
       " 'autobiography',\n",
       " 'automatically',\n",
       " 'automation',\n",
       " 'autonomy',\n",
       " 'autumn',\n",
       " 'available',\n",
       " 'avalanche',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'aversary',\n",
       " 'aversion',\n",
       " 'avery',\n",
       " 'avoid',\n",
       " 'avoidable',\n",
       " 'avon',\n",
       " 'avril',\n",
       " 'await',\n",
       " 'awaits',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'awash',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awesomeness',\n",
       " 'awesomness',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'awkwardness',\n",
       " 'awoke',\n",
       " 'awoken',\n",
       " 'ax',\n",
       " 'axel',\n",
       " 'axilla',\n",
       " 'ayan',\n",
       " 'ayumi',\n",
       " 'azealea',\n",
       " 'azul',\n",
       " 'ba',\n",
       " 'baachan',\n",
       " 'baba',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'babychaser',\n",
       " 'babydoll',\n",
       " 'babysat',\n",
       " 'babysit',\n",
       " 'babysitter',\n",
       " 'babysitting',\n",
       " 'bachelorette',\n",
       " 'back',\n",
       " 'backache',\n",
       " 'backdrop',\n",
       " 'backfire',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backlog',\n",
       " 'backpack',\n",
       " 'backpacker',\n",
       " 'backstage',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'backyard',\n",
       " 'bacuse',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badger',\n",
       " 'badly',\n",
       " 'badman',\n",
       " 'baffle',\n",
       " 'baffroom',\n",
       " 'bag',\n",
       " 'bagan',\n",
       " 'bagel',\n",
       " 'baggage',\n",
       " 'baggy',\n",
       " 'bah',\n",
       " 'baht',\n",
       " 'bail',\n",
       " 'bailey',\n",
       " 'bake',\n",
       " 'baker',\n",
       " 'baking',\n",
       " 'bal',\n",
       " 'balance',\n",
       " 'bald',\n",
       " 'balk',\n",
       " 'ball',\n",
       " 'ballet',\n",
       " 'ballistic',\n",
       " 'balloon',\n",
       " 'ballroom',\n",
       " 'balsamic',\n",
       " 'baltic',\n",
       " 'baltimore',\n",
       " 'bam',\n",
       " 'ban',\n",
       " 'banal',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bandaid',\n",
       " 'bandhu',\n",
       " 'bandwagon',\n",
       " 'bang',\n",
       " 'banishes',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'banking',\n",
       " 'banter',\n",
       " 'baptism',\n",
       " 'baptize',\n",
       " 'bar',\n",
       " 'barbecue',\n",
       " 'barbeque',\n",
       " 'barbie',\n",
       " 'barbies',\n",
       " 'barcial',\n",
       " 'bard',\n",
       " 'bare',\n",
       " 'barefoot',\n",
       " 'barely',\n",
       " 'bareminerals',\n",
       " 'bargain',\n",
       " 'barista',\n",
       " 'bark',\n",
       " 'barker',\n",
       " 'barn',\n",
       " 'barnog',\n",
       " 'baroque',\n",
       " 'barrage',\n",
       " 'barrier',\n",
       " 'barry',\n",
       " 'bartender',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'bashful',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'bask',\n",
       " 'basks',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'batchmates',\n",
       " 'bath',\n",
       " 'bathing',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'baton',\n",
       " 'battalion',\n",
       " 'batter',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'bauer',\n",
       " 'bay',\n",
       " 'bayou',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beachy',\n",
       " 'beacuse',\n",
       " 'bead',\n",
       " 'beak',\n",
       " 'beam',\n",
       " 'beanbag',\n",
       " 'bear',\n",
       " 'bearable',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beatles',\n",
       " 'beaubronz',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'becasue',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becsuse',\n",
       " 'becuz',\n",
       " 'bed',\n",
       " 'bedriacum',\n",
       " 'bedroom',\n",
       " 'bedside',\n",
       " 'bee',\n",
       " 'beef',\n",
       " 'beefy',\n",
       " 'beer',\n",
       " 'beet',\n",
       " 'befall',\n",
       " 'befc',\n",
       " 'befoe',\n",
       " 'beforehand',\n",
       " 'befriend',\n",
       " 'befuddle',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begleiter',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behaves',\n",
       " 'behaving',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'beholder',\n",
       " 'beijing',\n",
       " 'bein',\n",
       " 'beirut',\n",
       " 'belief',\n",
       " 'beliefs',\n",
       " 'believ',\n",
       " 'believe',\n",
       " 'believer',\n",
       " 'belittle',\n",
       " 'bell',\n",
       " 'belle',\n",
       " 'bellingham',\n",
       " 'bellman',\n",
       " 'belly',\n",
       " 'belmont',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'belongingness',\n",
       " 'beloved',\n",
       " 'belt',\n",
       " 'beluga',\n",
       " 'bemuse',\n",
       " 'ben',\n",
       " 'benadryl',\n",
       " 'bench',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=v.get_feature_names()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=xtr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=xts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=pd.DataFrame(Xtrain)\n",
    "Xtest=pd.DataFrame(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12099</th>\n",
       "      <th>12100</th>\n",
       "      <th>12101</th>\n",
       "      <th>12102</th>\n",
       "      <th>12103</th>\n",
       "      <th>12104</th>\n",
       "      <th>12105</th>\n",
       "      <th>12106</th>\n",
       "      <th>12107</th>\n",
       "      <th>12108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 12109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9      \\\n",
       "0        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "15995    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "15996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "15997    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "15998    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "15999    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       ...  12099  12100  12101  12102  12103  12104  12105  12106  12107  \\\n",
       "0      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "15995  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "15996  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "15997  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "15998  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "15999  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       12108  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "15995    0.0  \n",
       "15996    0.0  \n",
       "15997    0.0  \n",
       "15998    0.0  \n",
       "15999    0.0  \n",
       "\n",
       "[16000 rows x 12109 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimentionality reduction(keeping 10% of the features)\n",
    "select = SelectKBest(score_func=chi2, k=1200)\n",
    "fit = select.fit(Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX = fit.transform(Xtrain)\n",
    "TestX=fit.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX=pd.DataFrame(TrainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestX=pd.DataFrame(TestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling data to deal with imbalanced classes\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "x_train_res, y_train_res=ros.fit_sample(TrainX, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise    5362\n",
       "fear        5362\n",
       "joy         5362\n",
       "sadness     5362\n",
       "anger       5362\n",
       "love        5362\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new class breakdown\n",
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost modelling\n",
    "clf = XGBClassifier(random_state=42, seed=2, colsample_bytree=0.6, subsample=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=2, subsample=0.7,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.predict(TestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'sadness', 'sadness', ..., 'joy', 'joy', 'fear'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['true']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>fear</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     true\n",
       "0     sadness  sadness\n",
       "1     sadness  sadness\n",
       "2     sadness  sadness\n",
       "3         joy      joy\n",
       "4     sadness  sadness\n",
       "...       ...      ...\n",
       "1995    anger    anger\n",
       "1996    anger    anger\n",
       "1997      joy      joy\n",
       "1998      joy      joy\n",
       "1999     fear     fear\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test emotions vs predicted emotion\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.87      0.89      0.88       275\n",
      "        fear       0.83      0.82      0.83       224\n",
      "         joy       0.92      0.87      0.89       695\n",
      "        love       0.68      0.89      0.77       159\n",
      "     sadness       0.95      0.85      0.90       581\n",
      "    surprise       0.55      0.92      0.69        66\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.80      0.87      0.83      2000\n",
      "weighted avg       0.88      0.86      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
